{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "from datasets import Dataset, ClassLabel\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = snowflake.connector.connect(\n",
    "    user=os.environ[\"SF_USER\"],\n",
    "    password=os.environ[\"SF_PWD\"],\n",
    "    account=os.environ[\"SF_ACCOUNT\"],\n",
    "    database=os.environ[\"SF_DB\"],\n",
    "    schema=os.environ[\"SF_SCHEMA\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/j6_091hn32x0t8shq_lb0pxc0000gn/T/ipykernel_87235/2729437409.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# query the data from Snowflake and create a Pandas dataframe\n",
    "query = 'SELECT * FROM intent_dataset;'\n",
    "df = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TEXT</th>\n      <th>CATEGORY</th>\n      <th>SOURCE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I am still waiting on my card?</td>\n      <td>card_arrival</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What can I do if my card still hasn't arrived ...</td>\n      <td>card_arrival</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I have been waiting over a week. Is the card s...</td>\n      <td>card_arrival</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Can I track my card while it is in the process...</td>\n      <td>card_arrival</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>How do I know if I will get my card, or if it ...</td>\n      <td>card_arrival</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13078</th>\n      <td>If i'm not in the UK, can I still get a card?</td>\n      <td>country_support</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>13079</th>\n      <td>How many countries do you support?</td>\n      <td>country_support</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>13080</th>\n      <td>What countries do you do business in?</td>\n      <td>country_support</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>13081</th>\n      <td>What are the countries you operate in.</td>\n      <td>country_support</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>13082</th>\n      <td>Can the card be mailed and used in Europe?</td>\n      <td>country_support</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>13083 rows Ã— 3 columns</p>\n</div>",
      "text/plain": "                                                    TEXT         CATEGORY   \n0                         I am still waiting on my card?     card_arrival  \\\n1      What can I do if my card still hasn't arrived ...     card_arrival   \n2      I have been waiting over a week. Is the card s...     card_arrival   \n3      Can I track my card while it is in the process...     card_arrival   \n4      How do I know if I will get my card, or if it ...     card_arrival   \n...                                                  ...              ...   \n13078      If i'm not in the UK, can I still get a card?  country_support   \n13079                 How many countries do you support?  country_support   \n13080              What countries do you do business in?  country_support   \n13081             What are the countries you operate in.  country_support   \n13082         Can the card be mailed and used in Europe?  country_support   \n\n      SOURCE  \n0      train  \n1      train  \n2      train  \n3      train  \n4      train  \n...      ...  \n13078   test  \n13079   test  \n13080   test  \n13081   test  \n13082   test  \n\n[13083 rows x 3 columns]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast, Trainer, TrainingArguments\n",
    "from datasets import Features, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of unique labels in the 'category' column\n",
    "label_list = df['CATEGORY'].unique().tolist()\n",
    "\n",
    "# instantiate a ClassLabel object with the number of classes and the names of the labels\n",
    "num_classes = len(label_list)\n",
    "# create Hugging Face dataset\n",
    "features = Features({\"TEXT\": Value(\"string\"), \n",
    "                     \"CATEGORY\": ClassLabel(num_classes=num_classes, names=label_list),\n",
    "                     \"SOURCE\": Value(\"string\"),})\n",
    "dataset = Dataset.from_pandas(df, features=features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"CATEGORY\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6460c825813a496da0378644c1cc2621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Filter:   0%|          | 0/13083 [00:00<?, ? examples/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe5046381ad49f68d23335b255cfe44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Filter:   0%|          | 0/13083 [00:00<?, ? examples/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split dataset into train and test sets based on the value of \"SOURCE\"\n",
    "train_dataset = dataset.filter(lambda example: example[\"SOURCE\"] == \"train\")\n",
    "test_dataset = dataset.filter(lambda example: example[\"SOURCE\"] == \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2050f9b55b14043ab9283349f8dbf90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Map:   0%|          | 0/10003 [00:00<?, ? examples/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4453db540119412998b89181d2a3ae49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "Map:   0%|          | 0/3080 [00:00<?, ? examples/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['TEXT'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "This does not work and needs to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# load the pre-trained BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"philschmid/BERT-Banking77\")\n",
    "\n",
    "# load the pre-trained small BERT model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"philschmid/BERT-Banking77\", num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    evaluation_strategy='epoch',     # evaluate model after every epoch\n",
    "    learning_rate=2e-5,              # learning rate\n",
    "    per_device_train_batch_size=16,  # batch size for training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    num_train_epochs=3,              # number of training epochs\n",
    "    weight_decay=0.01,               # weight decay\n",
    "    push_to_hub=False,               # whether to upload the model checkpoint to the Hub\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# create the Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated model to be trained\n",
    "    args=training_args,                  # training arguments\n",
    "    train_dataset=train_dataset,         # the training dataset\n",
    "    eval_dataset=test_dataset            # the evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e470b7b9b75a44139d6f55bf7313e7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/1878 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.4833, 'learning_rate': 1.9893503727369543e-05, 'epoch': 0.02}\n",
      "{'loss': 5.4309, 'learning_rate': 1.9787007454739085e-05, 'epoch': 0.03}\n",
      "{'loss': 4.7968, 'learning_rate': 1.9680511182108627e-05, 'epoch': 0.05}\n",
      "{'loss': 4.2412, 'learning_rate': 1.957401490947817e-05, 'epoch': 0.06}\n",
      "{'loss': 3.7701, 'learning_rate': 1.946751863684771e-05, 'epoch': 0.08}\n",
      "{'loss': 3.4793, 'learning_rate': 1.9361022364217256e-05, 'epoch': 0.1}\n",
      "{'loss': 3.1575, 'learning_rate': 1.9254526091586797e-05, 'epoch': 0.11}\n",
      "{'loss': 2.6047, 'learning_rate': 1.914802981895634e-05, 'epoch': 0.13}\n",
      "{'loss': 2.3512, 'learning_rate': 1.904153354632588e-05, 'epoch': 0.14}\n",
      "{'loss': 2.0893, 'learning_rate': 1.8935037273695422e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8338, 'learning_rate': 1.8828541001064964e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8665, 'learning_rate': 1.8722044728434506e-05, 'epoch': 0.19}\n",
      "{'loss': 1.5325, 'learning_rate': 1.8615548455804048e-05, 'epoch': 0.21}\n",
      "{'loss': 1.5875, 'learning_rate': 1.850905218317359e-05, 'epoch': 0.22}\n",
      "{'loss': 1.2121, 'learning_rate': 1.840255591054313e-05, 'epoch': 0.24}\n",
      "{'loss': 1.2556, 'learning_rate': 1.8296059637912676e-05, 'epoch': 0.26}\n",
      "{'loss': 1.0155, 'learning_rate': 1.8189563365282218e-05, 'epoch': 0.27}\n",
      "{'loss': 0.9351, 'learning_rate': 1.808306709265176e-05, 'epoch': 0.29}\n",
      "{'loss': 0.9346, 'learning_rate': 1.79765708200213e-05, 'epoch': 0.3}\n",
      "{'loss': 0.8826, 'learning_rate': 1.7870074547390843e-05, 'epoch': 0.32}\n",
      "{'loss': 0.7716, 'learning_rate': 1.7763578274760385e-05, 'epoch': 0.34}\n",
      "{'loss': 0.9381, 'learning_rate': 1.7657082002129927e-05, 'epoch': 0.35}\n",
      "{'loss': 0.6343, 'learning_rate': 1.755058572949947e-05, 'epoch': 0.37}\n",
      "{'loss': 0.7147, 'learning_rate': 1.744408945686901e-05, 'epoch': 0.38}\n",
      "{'loss': 0.6561, 'learning_rate': 1.7337593184238552e-05, 'epoch': 0.4}\n",
      "{'loss': 0.7539, 'learning_rate': 1.7231096911608097e-05, 'epoch': 0.42}\n",
      "{'loss': 0.5551, 'learning_rate': 1.712460063897764e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4731, 'learning_rate': 1.7018104366347177e-05, 'epoch': 0.45}\n",
      "{'loss': 0.5156, 'learning_rate': 1.691160809371672e-05, 'epoch': 0.46}\n",
      "{'loss': 0.5661, 'learning_rate': 1.6805111821086264e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4843, 'learning_rate': 1.6698615548455806e-05, 'epoch': 0.5}\n",
      "{'loss': 0.4691, 'learning_rate': 1.6592119275825348e-05, 'epoch': 0.51}\n",
      "{'loss': 0.5377, 'learning_rate': 1.648562300319489e-05, 'epoch': 0.53}\n",
      "{'loss': 0.565, 'learning_rate': 1.637912673056443e-05, 'epoch': 0.54}\n",
      "{'loss': 0.3715, 'learning_rate': 1.6272630457933973e-05, 'epoch': 0.56}\n",
      "{'loss': 0.4656, 'learning_rate': 1.6166134185303515e-05, 'epoch': 0.58}\n",
      "{'loss': 0.374, 'learning_rate': 1.605963791267306e-05, 'epoch': 0.59}\n",
      "{'loss': 0.3491, 'learning_rate': 1.5953141640042598e-05, 'epoch': 0.61}\n",
      "{'loss': 0.3767, 'learning_rate': 1.584664536741214e-05, 'epoch': 0.62}\n",
      "{'loss': 0.4196, 'learning_rate': 1.5740149094781685e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3413, 'learning_rate': 1.5633652822151227e-05, 'epoch': 0.65}\n",
      "{'loss': 0.484, 'learning_rate': 1.552715654952077e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3466, 'learning_rate': 1.542066027689031e-05, 'epoch': 0.69}\n",
      "{'loss': 0.38, 'learning_rate': 1.5314164004259852e-05, 'epoch': 0.7}\n",
      "{'loss': 0.297, 'learning_rate': 1.5207667731629394e-05, 'epoch': 0.72}\n",
      "{'loss': 0.4001, 'learning_rate': 1.5101171458998936e-05, 'epoch': 0.73}\n",
      "{'loss': 0.5536, 'learning_rate': 1.4994675186368479e-05, 'epoch': 0.75}\n",
      "{'loss': 0.3035, 'learning_rate': 1.488817891373802e-05, 'epoch': 0.77}\n",
      "{'loss': 0.3743, 'learning_rate': 1.4781682641107562e-05, 'epoch': 0.78}\n",
      "{'loss': 0.3034, 'learning_rate': 1.4675186368477104e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2439, 'learning_rate': 1.4568690095846648e-05, 'epoch': 0.81}\n",
      "{'loss': 0.3016, 'learning_rate': 1.4462193823216188e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2364, 'learning_rate': 1.435569755058573e-05, 'epoch': 0.85}\n",
      "{'loss': 0.2378, 'learning_rate': 1.4249201277955273e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3925, 'learning_rate': 1.4142705005324815e-05, 'epoch': 0.88}\n",
      "{'loss': 0.3584, 'learning_rate': 1.4036208732694356e-05, 'epoch': 0.89}\n",
      "{'loss': 0.4035, 'learning_rate': 1.39297124600639e-05, 'epoch': 0.91}\n",
      "{'loss': 0.2854, 'learning_rate': 1.3823216187433442e-05, 'epoch': 0.93}\n",
      "{'loss': 0.3315, 'learning_rate': 1.3716719914802983e-05, 'epoch': 0.94}\n",
      "{'loss': 0.2405, 'learning_rate': 1.3610223642172523e-05, 'epoch': 0.96}\n",
      "{'loss': 0.2223, 'learning_rate': 1.3503727369542069e-05, 'epoch': 0.97}\n",
      "{'loss': 0.3678, 'learning_rate': 1.3397231096911609e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df829040f4724039baf403c783f85fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4730672538280487, 'eval_runtime': 1717.0914, 'eval_samples_per_second': 1.794, 'eval_steps_per_second': 0.029, 'epoch': 1.0}\n",
      "{'loss': 0.2064, 'learning_rate': 1.329073482428115e-05, 'epoch': 1.01}\n",
      "{'loss': 0.1509, 'learning_rate': 1.3184238551650694e-05, 'epoch': 1.02}\n",
      "{'loss': 0.2388, 'learning_rate': 1.3077742279020236e-05, 'epoch': 1.04}\n",
      "{'loss': 0.1106, 'learning_rate': 1.2971246006389777e-05, 'epoch': 1.05}\n",
      "{'loss': 0.177, 'learning_rate': 1.2864749733759319e-05, 'epoch': 1.07}\n",
      "{'loss': 0.0997, 'learning_rate': 1.2758253461128862e-05, 'epoch': 1.09}\n",
      "{'loss': 0.1512, 'learning_rate': 1.2651757188498404e-05, 'epoch': 1.1}\n",
      "{'loss': 0.1889, 'learning_rate': 1.2545260915867944e-05, 'epoch': 1.12}\n",
      "{'loss': 0.1728, 'learning_rate': 1.243876464323749e-05, 'epoch': 1.13}\n",
      "{'loss': 0.1883, 'learning_rate': 1.233226837060703e-05, 'epoch': 1.15}\n",
      "{'loss': 0.1458, 'learning_rate': 1.2225772097976571e-05, 'epoch': 1.17}\n",
      "{'loss': 0.1995, 'learning_rate': 1.2119275825346113e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1526, 'learning_rate': 1.2012779552715656e-05, 'epoch': 1.2}\n",
      "{'loss': 0.145, 'learning_rate': 1.1906283280085198e-05, 'epoch': 1.21}\n",
      "{'loss': 0.1304, 'learning_rate': 1.179978700745474e-05, 'epoch': 1.23}\n",
      "{'loss': 0.1139, 'learning_rate': 1.1693290734824283e-05, 'epoch': 1.25}\n",
      "{'loss': 0.2197, 'learning_rate': 1.1586794462193825e-05, 'epoch': 1.26}\n",
      "{'loss': 0.1629, 'learning_rate': 1.1480298189563365e-05, 'epoch': 1.28}\n",
      "{'loss': 0.1766, 'learning_rate': 1.1373801916932907e-05, 'epoch': 1.29}\n",
      "{'loss': 0.1288, 'learning_rate': 1.126730564430245e-05, 'epoch': 1.31}\n",
      "{'loss': 0.2243, 'learning_rate': 1.1160809371671992e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1399, 'learning_rate': 1.1054313099041534e-05, 'epoch': 1.34}\n",
      "{'loss': 0.1803, 'learning_rate': 1.0947816826411077e-05, 'epoch': 1.36}\n",
      "{'loss': 0.1256, 'learning_rate': 1.0841320553780619e-05, 'epoch': 1.37}\n",
      "{'loss': 0.1736, 'learning_rate': 1.073482428115016e-05, 'epoch': 1.39}\n",
      "{'loss': 0.1136, 'learning_rate': 1.06283280085197e-05, 'epoch': 1.41}\n",
      "{'loss': 0.1516, 'learning_rate': 1.0521831735889246e-05, 'epoch': 1.42}\n"
     ]
    }
   ],
   "source": [
    "# start the training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit ('sagemakerdeploy': conda)",
   "name": "python31010jvsc74a57bd0b184ee938e15fb1a29dec67e00cec5eb54a9efc4cf4a84aaaed928b9d8a5980c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}